# IOPaint Hugging Face éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•å°†IOPaintéƒ¨ç½²åˆ°Hugging Face Spacesï¼Œå®ç°äº‘ç«¯AIå›¾åƒä¿®å¤æœåŠ¡ã€‚Hugging Face Spacesæä¾›å…è´¹çš„GPUèµ„æºå’Œç®€å•çš„éƒ¨ç½²æµç¨‹ï¼Œæ˜¯æ‰˜ç®¡IOPaintæœåŠ¡çš„ç†æƒ³é€‰æ‹©ã€‚

## Hugging Face Spaces ç®€ä»‹

### ä»€ä¹ˆæ˜¯ Hugging Face Spaces
Hugging Face Spacesæ˜¯ä¸€ä¸ªç”¨äºæ‰˜ç®¡æœºå™¨å­¦ä¹ åº”ç”¨çš„å¹³å°ï¼Œæ”¯æŒï¼š
- **å…è´¹GPU**: æä¾›å…è´¹çš„GPUè®¡ç®—èµ„æº
- **å¤šæ¡†æ¶æ”¯æŒ**: æ”¯æŒGradioã€Streamlitã€Dockerç­‰
- **è‡ªåŠ¨éƒ¨ç½²**: Gitæ¨é€è‡ªåŠ¨éƒ¨ç½²
- **å…¬å¼€è®¿é—®**: æä¾›å…¬å¼€çš„APIç«¯ç‚¹

### èµ„æºé…ç½®
- **å…è´¹ç‰ˆ**: CPU 2æ ¸, 16GB RAM, ä¸´æ—¶å­˜å‚¨ ï¼ˆå…è´¹ï¼‰
- **ä»˜è´¹ç‰ˆ**: CPU Upgrade 8vCPU, 16GB RAM, $0.03/h (æ¨è)
- **ä»˜è´¹ç‰ˆ**: Navidia T4 small ,4v CPU,15GB RAM,16GB VRAM $0.6/h

## éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

https://huggingface.co/spaces/Sanster/iopaint-lama
https://huggingface.co/blog/zh/inference-endpoints-llm

### æ–¹æ¡ˆä¸€ï¼šDockeréƒ¨ç½²
```dockerfile
# ä¼˜åŠ¿ï¼š
- å®Œå…¨æ§åˆ¶ç¯å¢ƒé…ç½®
- æ€§èƒ½æœ€ä¼˜
- æ”¯æŒè‡ªå®šä¹‰API

# åŠ£åŠ¿ï¼š
- é…ç½®å¤æ‚
- æ„å»ºæ—¶é—´é•¿
- è°ƒè¯•å›°éš¾
```

## è¯¦ç»†éƒ¨ç½²æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºHugging Faceè´¦æˆ·
1. è®¿é—® https://huggingface.co
2. æ³¨å†Œè´¦æˆ·å¹¶éªŒè¯é‚®ç®±
3. åˆ›å»ºè®¿é—®ä»¤ç‰Œ (Settings â†’ Access Tokens)

### ç¬¬äºŒæ­¥ï¼šåˆ›å»ºSpace
1. ç‚¹å‡» "New Space"
2. å¡«å†™åŸºæœ¬ä¿¡æ¯ï¼š
   - **Space name**: `iopaint-service`
   - **License**: `Apache-2.0`
   - **SDK**: `Gradio`
   - **Hardware**: `CPU basic` (å…è´¹) æˆ– `CPU upgrade` (ä»˜è´¹) æˆ– `GPU T4` (ä»˜è´¹)  

## å…è´¹ä¸ä»˜è´¹æ–¹æ¡ˆâ¬‡ï¸

### å…è´¹æ–¹æ¡ˆ (Community)
- **ç¡¬ä»¶**: CPU 2æ ¸, 16GB RAM
- **é™åˆ¶**: 
  - å¤„ç†æ—¶é—´è¾ƒé•¿ (10-30ç§’)
  - å¯èƒ½æœ‰é˜Ÿåˆ—ç­‰å¾…
  - è‡ªåŠ¨ä¼‘çœ  (48å°æ—¶æ— æ´»åŠ¨)
- **é€‚ç”¨**: ä¸ªäººæµ‹è¯•ã€å°è§„æ¨¡ä½¿ç”¨
- **æˆæœ¬**: å®Œå…¨å…è´¹

### ä»˜è´¹æ–¹æ¡ˆå¯¹æ¯”

#### CPU upgrade ($0.033/å°æ—¶)
- **æ€§èƒ½**: å¤„ç†æ—¶é—´ 5-15ç§’
- **å†…å­˜**: 8vCPU, 16GB RAM
- **é€‚ç”¨**: ä¸­ç­‰è§„æ¨¡åº”ç”¨
- **æœˆæˆæœ¬**: ~$40 (24/7è¿è¡Œ)

#### GPU T4 ($0.60/å°æ—¶)
- **æ€§èƒ½**: å¤„ç†æ—¶é—´ 3-8ç§’
- **å†…å­˜**: 16GB GPUå†…å­˜
- **é€‚ç”¨**: ä¸­ç­‰è§„æ¨¡åº”ç”¨
- **æœˆæˆæœ¬**: ~$432 (24/7è¿è¡Œ)

#### GPU A10G ($1.05/å°æ—¶)
- **æ€§èƒ½**: å¤„ç†æ—¶é—´ 2-5ç§’
- **å†…å­˜**: 24GB GPUå†…å­˜
- **é€‚ç”¨**: é«˜æ€§èƒ½éœ€æ±‚
- **æœˆæˆæœ¬**: ~$756 (24/7è¿è¡Œ)

#### GPU A100 ($4.13/å°æ—¶)
- **æ€§èƒ½**: å¤„ç†æ—¶é—´ 1-3ç§’
- **å†…å­˜**: 40GB GPUå†…å­˜
- **é€‚ç”¨**: ä¼ä¸šçº§åº”ç”¨
- **æœˆæˆæœ¬**: ~$2,974 (24/7è¿è¡Œ)

### ç¬¬ä¸‰æ­¥ï¼šå‡†å¤‡éƒ¨ç½²æ–‡ä»¶

#### app.py (ä¸»åº”ç”¨æ–‡ä»¶)
```python
import gradio as gr
import numpy as np
from PIL import Image
import io
import base64
import requests
import os

# å®‰è£…IOPaint
os.system("pip install iopaint")

from iopaint import Config, new_model_manager
from iopaint.api import process_image

# åˆå§‹åŒ–æ¨¡å‹
config = Config(
    model_name="lama",
    device="cuda" if gr.utils.get_device() == "cuda" else "cpu",
    model_dir="./models"
)
model_manager = new_model_manager(config)

def inpaint_image(image, mask):
    """
    å›¾åƒä¿®å¤å‡½æ•°
    """
    try:
        # å¤„ç†è¾“å…¥å›¾åƒ
        if isinstance(image, str):
            image = Image.open(io.BytesIO(base64.b64decode(image)))
        if isinstance(mask, str):
            mask = Image.open(io.BytesIO(base64.b64decode(mask)))
        
        # è°ƒç”¨IOPaintå¤„ç†
        result = process_image(
            model_manager=model_manager,
            image=image,
            mask=mask,
            config=config
        )
        
        return result
    except Exception as e:
        raise gr.Error(f"å¤„ç†å¤±è´¥: {str(e)}")

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="é­”æœ¯æ©¡çš®æ“¦ - IOPaintæœåŠ¡") as app:
    gr.Markdown("# ğŸ¨ é­”æœ¯æ©¡çš®æ“¦ AIå›¾åƒä¿®å¤æœåŠ¡")
    gr.Markdown("ä¸Šä¼ å›¾ç‰‡å’Œè’™ç‰ˆï¼ŒAIå°†æ™ºèƒ½ç§»é™¤ä¸éœ€è¦çš„ç‰©ä½“")
    
    with gr.Row():
        with gr.Column():
            image_input = gr.Image(
                label="åŸå§‹å›¾ç‰‡",
                type="pil",
                height=400
            )
            mask_input = gr.Image(
                label="è’™ç‰ˆ (ç™½è‰²=ç§»é™¤ï¼Œé»‘è‰²=ä¿ç•™)",
                type="pil",
                height=400
            )
            
        with gr.Column():
            output_image = gr.Image(
                label="å¤„ç†ç»“æœ",
                height=400
            )
            
    with gr.Row():
        clear_btn = gr.Button("æ¸…é™¤", variant="secondary")
        process_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
    
    # ç»‘å®šäº‹ä»¶
    process_btn.click(
        fn=inpaint_image,
        inputs=[image_input, mask_input],
        outputs=output_image
    )
    
    clear_btn.click(
        fn=lambda: (None, None, None),
        outputs=[image_input, mask_input, output_image]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
```

#### requirements.txt
```txt
iopaint>=1.3.0
torch>=2.0.0
torchvision>=0.15.0
Pillow>=9.0.0
numpy>=1.21.0
opencv-python>=4.5.0
gradio>=4.0.0
```

#### README.md
```markdown
---
title: IOPaint Magic Eraser
emoji: ğŸ¨
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.0.0
app_file: app.py
pinned: false
license: apache-2.0
---

# IOPaint Magic Eraser

AI-powered image inpainting service using IOPaint.

## Features
- Remove unwanted objects from images
- Multiple AI models support
- High-quality results
- Easy-to-use interface

## API Usage
```python
import requests

response = requests.post(
    "https://your-space-name.hf.space/api/predict",
    json={
        "data": [image_base64, mask_base64]
    }
)
```
```

### ç¬¬å››æ­¥ï¼šéƒ¨ç½²åˆ°Hugging Face

#### æ–¹æ³•ä¸€ï¼šWebç•Œé¢ä¸Šä¼ 
1. åœ¨Spaceé¡µé¢ç‚¹å‡» "Files"
2. ä¸Šä¼  `app.py`, `requirements.txt`, `README.md`
3. ç­‰å¾…è‡ªåŠ¨æ„å»ºå’Œéƒ¨ç½²

#### æ–¹æ³•äºŒï¼šGitæ¨é€
```bash
# å…‹éš†ä»“åº“
git clone https://huggingface.co/spaces/your-username/iopaint-service
cd iopaint-service

# æ·»åŠ æ–‡ä»¶
cp app.py requirements.txt README.md ./

# æäº¤æ¨é€
git add .
git commit -m "Initial IOPaint deployment"
git push
```

### ç¬¬äº”æ­¥ï¼šé…ç½®å’Œä¼˜åŒ–

#### ç¯å¢ƒå˜é‡é…ç½®
åœ¨Spaceè®¾ç½®ä¸­æ·»åŠ ï¼š
```
HF_TOKEN=your_huggingface_token
MODEL_CACHE_DIR=/tmp/models
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
```

#### æ€§èƒ½ä¼˜åŒ–
```python
# æ¨¡å‹ç¼“å­˜
@gr.cache
def load_model():
    return new_model_manager(config)

# æ‰¹å¤„ç†æ”¯æŒ
def batch_inpaint(images, masks):
    results = []
    for img, mask in zip(images, masks):
        result = inpaint_image(img, mask)
        results.append(result)
    return results
```

## APIé›†æˆæŒ‡å—

### è·å–APIç«¯ç‚¹
éƒ¨ç½²æˆåŠŸåï¼ŒGradioä¼šè‡ªåŠ¨ç”ŸæˆAPIç«¯ç‚¹ï¼š
```
https://your-username-iopaint-service.hf.space/api/predict
```

### å‰ç«¯é›†æˆç¤ºä¾‹
```typescript
// è°ƒç”¨Hugging Face Space API
async function callIOPaintAPI(imageBase64: string, maskBase64: string) {
  const response = await fetch(
    'https://your-username-iopaint-service.hf.space/api/predict',
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        data: [imageBase64, maskBase64]
      })
    }
  );
  
  const result = await response.json();
  return result.data[0]; // è¿”å›å¤„ç†åçš„å›¾åƒ
}
```

### é”™è¯¯å¤„ç†
```typescript
try {
  const result = await callIOPaintAPI(image, mask);
  setProcessedImage(result);
} catch (error) {
  if (error.message.includes('queue')) {
    // å¤„ç†é˜Ÿåˆ—ç­‰å¾…
    setStatus('æ’é˜Ÿä¸­ï¼Œè¯·ç¨å€™...');
  } else if (error.message.includes('timeout')) {
    // å¤„ç†è¶…æ—¶
    setError('å¤„ç†è¶…æ—¶ï¼Œè¯·é‡è¯•');
  } else {
    setError('å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾åƒæ ¼å¼');
  }
}
```


### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

#### 1. æŒ‰éœ€å¯åŠ¨
```python
# å®ç°è‡ªåŠ¨ä¼‘çœ å’Œå”¤é†’
import time
import threading

class AutoSleepManager:
    def __init__(self, idle_timeout=1800):  # 30åˆ†é’Ÿ
        self.last_request = time.time()
        self.idle_timeout = idle_timeout
        
    def update_activity(self):
        self.last_request = time.time()
        
    def should_sleep(self):
        return time.time() - self.last_request > self.idle_timeout
```

#### 2. è¯·æ±‚é˜Ÿåˆ—
```python
import asyncio
from queue import Queue

class RequestQueue:
    def __init__(self, max_concurrent=3):
        self.queue = Queue()
        self.max_concurrent = max_concurrent
        self.processing = 0
        
    async def process_request(self, image, mask):
        if self.processing >= self.max_concurrent:
            await self.queue.put((image, mask))
        else:
            return await self.inpaint(image, mask)
```

#### 3. ç»“æœç¼“å­˜
```python
import hashlib
import pickle

class ResultCache:
    def __init__(self, cache_dir="/tmp/cache"):
        self.cache_dir = cache_dir
        
    def get_cache_key(self, image, mask):
        image_hash = hashlib.md5(image.tobytes()).hexdigest()
        mask_hash = hashlib.md5(mask.tobytes()).hexdigest()
        return f"{image_hash}_{mask_hash}"
        
    def get_cached_result(self, key):
        cache_file = f"{self.cache_dir}/{key}.pkl"
        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
```

## ç›‘æ§å’Œç»´æŠ¤

### æ€§èƒ½ç›‘æ§
```python
import time
import logging

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'average_processing_time': 0,
            'error_rate': 0
        }
        
    def log_request(self, processing_time, success=True):
        self.metrics['total_requests'] += 1
        if success:
            self.metrics['successful_requests'] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        current_avg = self.metrics['average_processing_time']
        total = self.metrics['total_requests']
        self.metrics['average_processing_time'] = (
            (current_avg * (total - 1) + processing_time) / total
        )
        
        # æ›´æ–°é”™è¯¯ç‡
        self.metrics['error_rate'] = (
            1 - self.metrics['successful_requests'] / total
        )
```

### æ—¥å¿—ç®¡ç†
```python
import logging
import json

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/iopaint.log'),
        logging.StreamHandler()
    ]
)

def log_request(image_size, processing_time, success, error=None):
    log_data = {
        'timestamp': time.time(),
        'image_size': image_size,
        'processing_time': processing_time,
        'success': success,
        'error': str(error) if error else None
    }
    logging.info(json.dumps(log_data))
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å‹åŠ è½½å¤±è´¥
```python
# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œæƒé™
try:
    model_manager = new_model_manager(config)
except Exception as e:
    logging.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    # å°è¯•é‡æ–°ä¸‹è½½æ¨¡å‹
    os.system("iopaint download --model lama")
```

#### 2. GPUå†…å­˜ä¸è¶³
```python
# è§£å†³æ–¹æ¡ˆï¼šå¯ç”¨CPUå¸è½½
config = Config(
    model_name="lama",
    device="cuda",
    cpu_offload=True,  # å¯ç”¨CPUå¸è½½
    low_mem=True       # ä½å†…å­˜æ¨¡å¼
)
```

#### 3. å¤„ç†è¶…æ—¶
```python
# è§£å†³æ–¹æ¡ˆï¼šè®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
import signal

def timeout_handler(signum, frame):
    raise TimeoutError("å¤„ç†è¶…æ—¶")

signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(30)  # 30ç§’è¶…æ—¶

try:
    result = inpaint_image(image, mask)
finally:
    signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
```

## æ”¶è´¹æ¨¡å¼è®¾è®¡

### APIè°ƒç”¨è®¡è´¹
```python
# å®ç°åŸºäºä»¤ç‰Œçš„è®¡è´¹ç³»ç»Ÿ
class BillingManager:
    def __init__(self):
        self.rates = {
            'free': {'daily_limit': 10, 'cost_per_call': 0},
            'basic': {'daily_limit': 100, 'cost_per_call': 0.1},
            'pro': {'daily_limit': 1000, 'cost_per_call': 0.05},
            'enterprise': {'daily_limit': -1, 'cost_per_call': 0.02}
        }

    def check_quota(self, user_id, plan='free'):
        # æ£€æŸ¥ç”¨æˆ·é…é¢
        usage = self.get_daily_usage(user_id)
        limit = self.rates[plan]['daily_limit']
        return limit == -1 or usage < limit

    def charge_request(self, user_id, plan='free'):
        # è®°å½•ä½¿ç”¨é‡å’Œè´¹ç”¨
        cost = self.rates[plan]['cost_per_call']
        self.record_usage(user_id, cost)
        return cost
```

### è®¢é˜…ç®¡ç†
```python
# ç”¨æˆ·è®¢é˜…çŠ¶æ€ç®¡ç†
class SubscriptionManager:
    def __init__(self):
        self.plans = {
            'free': {'price': 0, 'features': ['basic_inpaint']},
            'basic': {'price': 29, 'features': ['basic_inpaint', 'hd_processing']},
            'pro': {'price': 99, 'features': ['all_models', 'batch_processing', 'api_access']},
            'enterprise': {'price': 299, 'features': ['priority_support', 'custom_models']}
        }

    def get_user_plan(self, user_id):
        # è·å–ç”¨æˆ·å½“å‰è®¢é˜…è®¡åˆ’
        return self.query_user_subscription(user_id)

    def upgrade_plan(self, user_id, new_plan):
        # å‡çº§ç”¨æˆ·è®¢é˜…
        return self.update_subscription(user_id, new_plan)
```

## é«˜çº§åŠŸèƒ½å®ç°

### å¤šæ¨¡å‹æ”¯æŒ
```python
# æ”¯æŒå¤šä¸ªAIæ¨¡å‹çš„åŠ¨æ€åˆ‡æ¢
class MultiModelManager:
    def __init__(self):
        self.models = {
            'lama': {'speed': 'fast', 'quality': 'good', 'cost': 1},
            'ldm': {'speed': 'slow', 'quality': 'excellent', 'cost': 3},
            'mat': {'speed': 'medium', 'quality': 'very_good', 'cost': 2}
        }
        self.loaded_models = {}

    def get_model(self, model_name, user_plan='free'):
        # æ ¹æ®ç”¨æˆ·è®¡åˆ’è¿”å›å¯ç”¨æ¨¡å‹
        if user_plan == 'free' and model_name != 'lama':
            raise ValueError("å…è´¹ç”¨æˆ·åªèƒ½ä½¿ç”¨LaMaæ¨¡å‹")

        if model_name not in self.loaded_models:
            self.loaded_models[model_name] = self.load_model(model_name)

        return self.loaded_models[model_name]
```

### æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡å›¾åƒå¤„ç†åŠŸèƒ½
async def batch_inpaint(images, masks, model_name='lama'):
    results = []
    for i, (image, mask) in enumerate(zip(images, masks)):
        try:
            result = await inpaint_image(image, mask, model_name)
            results.append({
                'index': i,
                'success': True,
                'result': result
            })
        except Exception as e:
            results.append({
                'index': i,
                'success': False,
                'error': str(e)
            })
    return results
```

## éƒ¨ç½²æœ€ä½³å®è·µ

### 1. ç¯å¢ƒé…ç½®
```yaml
# docker-compose.yml (æœ¬åœ°æµ‹è¯•)
version: '3.8'
services:
  iopaint:
    build: .
    ports:
      - "7860:7860"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_CACHE_DIR=/app/models
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### 2. è´Ÿè½½å‡è¡¡
```python
# å®ç°ç®€å•çš„è´Ÿè½½å‡è¡¡
import random

class LoadBalancer:
    def __init__(self, endpoints):
        self.endpoints = endpoints
        self.health_status = {ep: True for ep in endpoints}

    def get_healthy_endpoint(self):
        healthy_endpoints = [
            ep for ep, status in self.health_status.items()
            if status
        ]
        if not healthy_endpoints:
            raise Exception("æ²¡æœ‰å¯ç”¨çš„æœåŠ¡ç«¯ç‚¹")
        return random.choice(healthy_endpoints)

    async def health_check(self):
        for endpoint in self.endpoints:
            try:
                response = await requests.get(f"{endpoint}/health")
                self.health_status[endpoint] = response.status_code == 200
            except:
                self.health_status[endpoint] = False
```

### 3. ç¼“å­˜ç­–ç•¥
```python
# Redisç¼“å­˜å®ç°
import redis
import pickle
import hashlib

class RedisCache:
    def __init__(self, host='localhost', port=6379, db=0):
        self.redis_client = redis.Redis(host=host, port=port, db=db)
        self.cache_ttl = 3600  # 1å°æ—¶è¿‡æœŸ

    def get_cache_key(self, image_data, mask_data, model_name):
        combined = image_data + mask_data + model_name.encode()
        return hashlib.sha256(combined).hexdigest()

    def get_cached_result(self, cache_key):
        cached = self.redis_client.get(cache_key)
        if cached:
            return pickle.loads(cached)
        return None

    def cache_result(self, cache_key, result):
        serialized = pickle.dumps(result)
        self.redis_client.setex(cache_key, self.cache_ttl, serialized)
```

## ç›‘æ§å’Œåˆ†æ

### æ€§èƒ½æŒ‡æ ‡æ”¶é›†
```python
# é›†æˆPrometheusç›‘æ§
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# å®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter('iopaint_requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('iopaint_request_duration_seconds', 'Request duration')
ACTIVE_USERS = Gauge('iopaint_active_users', 'Number of active users')
GPU_UTILIZATION = Gauge('iopaint_gpu_utilization_percent', 'GPU utilization')

def monitor_request(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            REQUEST_COUNT.labels(method='POST', endpoint='/inpaint').inc()
            return result
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    return wrapper

# å¯åŠ¨ç›‘æ§æœåŠ¡å™¨
start_http_server(8000)
```

### ç”¨æˆ·è¡Œä¸ºåˆ†æ
```python
# ç”¨æˆ·ä½¿ç”¨æƒ…å†µç»Ÿè®¡
class AnalyticsManager:
    def __init__(self):
        self.events = []

    def track_event(self, user_id, event_type, properties=None):
        event = {
            'user_id': user_id,
            'event_type': event_type,
            'timestamp': time.time(),
            'properties': properties or {}
        }
        self.events.append(event)

        # å‘é€åˆ°åˆ†ææœåŠ¡
        self.send_to_analytics(event)

    def get_usage_stats(self, start_date, end_date):
        # ç”Ÿæˆä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š
        return {
            'total_requests': len(self.events),
            'unique_users': len(set(e['user_id'] for e in self.events)),
            'popular_models': self.get_model_usage_stats(),
            'peak_hours': self.get_peak_usage_hours()
        }
```

## å®‰å…¨å’Œåˆè§„

### APIå®‰å…¨
```python
# JWTä»¤ç‰ŒéªŒè¯
import jwt
from functools import wraps

def require_auth(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        token = request.headers.get('Authorization')
        if not token:
            return {'error': 'Missing authorization token'}, 401

        try:
            token = token.replace('Bearer ', '')
            payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
            request.user_id = payload['user_id']
        except jwt.InvalidTokenError:
            return {'error': 'Invalid token'}, 401

        return f(*args, **kwargs)
    return decorated_function

@require_auth
def inpaint_endpoint():
    # å—ä¿æŠ¤çš„APIç«¯ç‚¹
    pass
```

### å†…å®¹è¿‡æ»¤
```python
# å›¾åƒå†…å®¹å®‰å…¨æ£€æŸ¥
import cv2
import numpy as np

class ContentFilter:
    def __init__(self):
        # åŠ è½½å†…å®¹æ£€æµ‹æ¨¡å‹
        self.nsfw_detector = self.load_nsfw_detector()

    def is_safe_image(self, image):
        # æ£€æŸ¥å›¾åƒæ˜¯å¦åŒ…å«ä¸å½“å†…å®¹
        try:
            score = self.nsfw_detector.predict(image)
            return score < 0.7  # é˜ˆå€¼å¯è°ƒ
        except:
            return True  # æ£€æµ‹å¤±è´¥æ—¶é»˜è®¤é€šè¿‡

    def filter_request(self, image, mask):
        if not self.is_safe_image(image):
            raise ValueError("å›¾åƒåŒ…å«ä¸å½“å†…å®¹")
        return True
```

## æ€»ç»“

é€šè¿‡Hugging Face Spaceséƒ¨ç½²IOPaintæœåŠ¡å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **ç®€å•éƒ¨ç½²**: æ— éœ€å¤æ‚çš„æœåŠ¡å™¨é…ç½®
2. **å…è´¹èµ„æº**: æä¾›å…è´¹çš„GPUè®¡ç®—èµ„æº
3. **è‡ªåŠ¨æ‰©å®¹**: æ ¹æ®éœ€æ±‚è‡ªåŠ¨åˆ†é…èµ„æº
4. **å…¨çƒè®¿é—®**: CDNåŠ é€Ÿï¼Œä½å»¶è¿Ÿè®¿é—®
5. **æ˜“äºç»´æŠ¤**: è‡ªåŠ¨åŒ–çš„éƒ¨ç½²å’Œæ›´æ–°

### æˆæœ¬æ•ˆç›Šåˆ†æ
- **å…è´¹æ–¹æ¡ˆ**: é€‚åˆä¸ªäººç”¨æˆ·å’Œå°è§„æ¨¡æµ‹è¯•
- **ä»˜è´¹æ–¹æ¡ˆ**: ä¼ä¸šçº§åº”ç”¨çš„æ€§ä»·æ¯”é€‰æ‹©
- **æ··åˆéƒ¨ç½²**: ç»“åˆå…è´¹å’Œä»˜è´¹èµ„æºçš„æœ€ä¼˜ç­–ç•¥

### æŠ€æœ¯ä¼˜åŠ¿
- **é«˜å¯ç”¨æ€§**: 99.9%çš„æœåŠ¡å¯ç”¨æ€§
- **å¼¹æ€§æ‰©å±•**: æ ¹æ®è´Ÿè½½è‡ªåŠ¨è°ƒæ•´èµ„æº
- **å…¨çƒéƒ¨ç½²**: å¤šåœ°åŒºéƒ¨ç½²é™ä½å»¶è¿Ÿ
- **å®‰å…¨å¯é **: ä¼ä¸šçº§å®‰å…¨ä¿éšœ

é€šè¿‡åˆç†çš„é…ç½®å’Œä¼˜åŒ–ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªé«˜æ€§èƒ½ã€ä½æˆæœ¬çš„AIå›¾åƒä¿®å¤æœåŠ¡ï¼Œä¸ºé­”æœ¯æ©¡çš®æ“¦åº”ç”¨æä¾›å¼ºå¤§çš„åç«¯æ”¯æŒã€‚
